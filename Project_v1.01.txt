import numpy as np
import cv2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda, Subtract, UpSampling2D, concatenate
from tensorflow.keras.optimizers import Adam
import tensorflow.keras.backend as K
import matplotlib.pyplot as plt
from skimage import exposure
from google.colab import files
import os

# Helper Functions
def preprocess_image(image_path, size=(256, 256)):
    """
    Preprocess the input image: resizing and normalization.
    """
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB
    image = cv2.resize(image, size) # Resize to model input size
    image = image / 255.0 # Normalize pixel values
    return image

def siamese_network_with_mask(input_shape):
    """
    Build a Siamese network with a U-Net decoder to output both similarity score and difference mask.
    """
    def base_network(input_shape):
        """Base network for feature extraction."""
        inputs = Input(shape=input_shape)
        x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
        x = MaxPooling2D((2, 2))(x)
        x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
        x = MaxPooling2D((2, 2))(x)
        x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
        x = MaxPooling2D((2, 2))(x)
        return Model(inputs, x)

    def decoder_network(encoded_diff):
        """U-Net decoder to generate a difference mask."""
        x = UpSampling2D((2, 2))(encoded_diff)
        x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        mask = Conv2D(1, (1, 1), activation='sigmoid', padding='same', name='difference_mask')(x)
        return mask

    # Inputs for the two images
    input_a = Input(shape=input_shape)
    input_b = Input(shape=input_shape)

    # Shared feature extractor
    shared_network = base_network(input_shape)

    # Feature vectors for both images
    features_a = shared_network(input_a)
    features_b = shared_network(input_b)

    # Difference between the two feature maps
    diff = Subtract()([features_a, features_b])
    diff_flattened = Flatten()(diff)

    # Similarity score
    similarity_dense = Dense(128, activation='relu')(diff_flattened)
    similarity_score = Dense(1, activation='sigmoid', name='similarity_score')(similarity_dense)

    # Difference mask
    difference_mask = decoder_network(diff)

    # Siamese model
    model = Model([input_a, input_b], [similarity_score, difference_mask])
    model.compile(optimizer=Adam(learning_rate=0.001),
        loss={'similarity_score': 'binary_crossentropy', 'difference_mask': 'binary_crossentropy'},
        metrics={'similarity_score': 'accuracy'})
    return model

# File Uploads
print("Please upload the two images (before and after).")
uploaded_files = files.upload()

# Save Uploaded Files
image_paths = list(uploaded_files.keys())
if len(image_paths) != 2:
    raise ValueError("Please upload exactly two images: one for 'before' and one for 'after'.")

# Preprocess Images
image1 = preprocess_image(image_paths[0])
image2 = preprocess_image(image_paths[1])

# Expand dimensions for batch processing
image1 = np.expand_dims(image1, axis=0)
image2 = np.expand_dims(image2, axis=0)

# Simulated Training Data (Placeholder for Actual Training)
X1_train = np.random.rand(10, 256, 256, 3) # Random placeholder training images
X2_train = np.random.rand(10, 256, 256, 3) # Random placeholder comparison images
Y_train_similarity = np.random.randint(0, 2, (10, 1)) # Random binary labels
Y_train_mask = np.random.rand(10, 256, 256, 1)) # Random placeholder masks

# Ensure consistency in dimensions
Y_train_similarity = np.expand_dims(Y_train_similarity, axis=-1) # Expand dimensions if necessary

# Train Siamese Network
input_shape = (256, 256, 3)
siamese_model = siamese_network_with_mask(input_shape)
siamese_model.fit([X1_train, X2_train],
    {'similarity_score': Y_train_similarity, 'difference_mask': Y_train_mask},
    epochs=10,
    batch_size=2,
    verbose=1)

# Predict Similarity and Difference Mask
similarity_score, predicted_mask = siamese_model.predict([image1, image2])

# Visualize Results
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.title("Image Before")
plt.imshow(image1[0])

plt.subplot(1, 3, 2)
plt.title("Image After")
plt.imshow(image2[0])

plt.subplot(1, 3, 3)
plt.title("Predicted Difference Mask")
plt.imshow(predicted_mask[0, :, :, 0], cmap="hot")

plt.suptitle(f"Similarity Score: {similarity_score[0, 0]:.2f}")
plt.show()