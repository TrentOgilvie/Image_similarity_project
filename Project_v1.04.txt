import numpy as np
import cv2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Lambda, BatchNormalization, concatenate
import tensorflow.keras.backend as K
from tensorflow.keras.applications import VGG16
import matplotlib.pyplot as plt
from google.colab import files
import os

def preprocess_image(image_path, size=(256, 256)):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = cv2.resize(image, size)
    image = image / 255.0
    return image

def generate_training_data(num_pairs=1000, size=(256, 256)):
    X1 = []
    X2 = []
    Y = []

    for i in range(num_pairs):
        base_img = np.random.rand(size[0], size[1], 3)

        if i % 2 == 0:
            noise = np.random.normal(0, 0.02, size=(size[0], size[1], 3))
            modified_img = np.clip(base_img + noise, 0, 1)
            similarity = np.random.uniform(0.8, 1.0)
        else:
            modified_img = np.random.rand(size[0], size[1], 3)
            similarity = np.random.uniform(0.0, 0.2)

        X1.append(base_img)
        X2.append(modified_img)
        Y.append(similarity)

    return np.array(X1), np.array(X2), np.array(Y)

def siamese_network(input_shape=(256, 256, 3)):
    def create_base_network(input_shape):
        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)

        for layer in base_model.layers[-12:]:
            layer.trainable = True

        x = base_model.output
        x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)
        x = BatchNormalization()(x)
        x = MaxPooling2D((2, 2))(x)
        feature_maps = x  # Save the feature maps before flattening
        x = Flatten()(x)
        x = Dense(1024, activation='relu')(x)
        x = BatchNormalization()(x)
        x = Dense(512, activation='relu')(x)
        return Model(base_model.input, [x, feature_maps])

    base_network = create_base_network(input_shape)

    input_a = Input(shape=input_shape)
    input_b = Input(shape=input_shape)

    processed_a, feature_maps_a = base_network(input_a)
    processed_b, feature_maps_b = base_network(input_b)

    def cosine_similarity(vects):
        x, y = vects
        x = K.l2_normalize(x, axis=-1)
        y = K.l2_normalize(y, axis=-1)
        return K.sum(x * y, axis=-1, keepdims=True)

    similarity = Lambda(cosine_similarity)([processed_a, processed_b])

    model = Model([input_a, input_b], similarity)
    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])
    return model, base_network

# File Uploads
print("Please upload the two images (before and after).")
uploaded_files = files.upload()

# Save Uploaded Files
image_paths = list(uploaded_files.keys())
if len(image_paths) != 2:
    raise ValueError("Please upload exactly two images: one for 'before' and one for 'after'.")

# Preprocess Images
image1 = preprocess_image(image_paths[0])
image2 = preprocess_image(image_paths[1])

# Create the Siamese network
siamese, base_network = siamese_network()

# Generate better training data
print("\nGenerating training data...")
X1_train, X2_train, Y_train = generate_training_data(num_pairs=1000)

# Train the network
print("\nTraining Siamese Network...")
siamese.fit(
    [X1_train, X2_train],
    Y_train,
    epochs=20,
    batch_size=32,
    validation_split=0.2,
    verbose=1
)

# Calculate similarity between the two uploaded images
similarity_score = siamese.predict([
    np.expand_dims(image1, axis=0),
    np.expand_dims(image2, axis=0)
])[0][0]

# Extract feature maps
_, feature_maps1 = base_network.predict(np.expand_dims(image1, axis=0))
_, feature_maps2 = base_network.predict(np.expand_dims(image2, axis=0))

# Compute difference map
diff_map = np.abs(feature_maps1 - feature_maps2)
diff_map = np.mean(diff_map, axis=-1)  # Average across channels
diff_map = (diff_map - diff_map.min()) / (diff_map.max() - diff_map.min())  # Normalize

# Display the results
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.title("Image Before")
plt.imshow(image1)
plt.axis('off')

plt.subplot(1, 3, 2)
plt.title("Image After")
plt.imshow(image2)
plt.axis('off')

plt.subplot(1, 3, 3)
plt.title(f"Difference Map\nSimilarity Score: {similarity_score:.3f}")
plt.imshow(diff_map[0], cmap='hot')
plt.colorbar(label='Difference Magnitude')
plt.axis('off')

plt.tight_layout()
plt.show()

print(f"\nSimilarity Score: {similarity_score:.3f}")
print("Interpretation:")
print("0.0-0.2: Very Different")
print("0.2-0.8: Moderately Similar")
print("0.8-1.0: Very Similar")