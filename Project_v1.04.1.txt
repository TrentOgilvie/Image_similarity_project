import numpy as np
import cv2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Lambda, BatchNormalization
import tensorflow.keras.backend as K
from tensorflow.keras.applications import VGG16
import matplotlib.pyplot as plt
from google.colab import files
import os
import gc  # Garbage collector

def preprocess_image(image_path, size=(224, 224)):  # Using a smaller image size
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = cv2.resize(image, size)
    image = image / 255.0
    return image

def generate_training_data(num_pairs=500, size=(224, 224)):  # Reduced number of pairs
    X1 = []
    X2 = []
    Y = []

    for i in range(num_pairs):
        base_img = np.random.rand(size[0], size[1], 3)

        if i % 2 == 0:
            noise = np.random.normal(0, 0.02, size=(size[0], size[1], 3))
            modified_img = np.clip(base_img + noise, 0, 1)
            similarity = np.random.uniform(0.8, 1.0)
        else:
            modified_img = np.random.rand(size[0], size[1], 3)
            similarity = np.random.uniform(0.0, 0.2)

        X1.append(base_img)
        X2.append(modified_img)
        Y.append(similarity)

    return np.array(X1), np.array(X2), np.array(Y)

def siamese_network(input_shape=(224, 224, 3)):
    def create_base_network(input_shape):
        # Use a smaller, more memory-efficient architecture
        # Option 1: Use fewer layers from VGG16
        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)
        # Freeze early layers to reduce memory during training
        for layer in base_model.layers[:10]:
            layer.trainable = False
        # Extract features from block2_conv2 for detailed maps
        early_features = base_model.get_layer('block2_conv2').output
        # Simplified top layers
        x = base_model.output
        x = Flatten()(x)
        x = Dense(512, activation='relu')(x)  # Smaller dense layer
        return Model(base_model.input, [x, early_features])

    base_network = create_base_network(input_shape)

    input_a = Input(shape=input_shape)
    input_b = Input(shape=input_shape)

    processed_a, feature_maps_a = base_network(input_a)
    processed_b, feature_maps_b = base_network(input_b)

    def cosine_similarity(vects):
        x, y = vects
        x = K.l2_normalize(x, axis=-1)
        y = K.l2_normalize(y, axis=-1)
        return K.sum(x * y, axis=-1, keepdims=True)

    similarity = Lambda(cosine_similarity)([processed_a, processed_b])

    model = Model([input_a, input_b], similarity)
    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])
    return model, base_network

# File Uploads
print("Please upload the two images (before and after).")
uploaded_files = files.upload()

# Save Uploaded Files
image_paths = list(uploaded_files.keys())
if len(image_paths) != 2:
    raise ValueError("Please upload exactly two images: one for 'before' and one for 'after'.")

# Preprocess Images
image1 = preprocess_image(image_paths[0])
image2 = preprocess_image(image_paths[1])

# Create the Siamese network
siamese, base_network = siamese_network()

# Generate training data in batches to save memory
batch_size = 50  # Process in smaller batches
num_batches = 10
print("\nGenerating and training with data batches...")

for batch in range(num_batches):
    print(f"Processing batch {batch+1}/{num_batches}")
    # Generate a smaller batch of training data
    X1_train, X2_train, Y_train = generate_training_data(num_pairs=batch_size)
    # Train on this batch
    siamese.fit(
        [X1_train, X2_train],
        Y_train,
        epochs=2,  # Fewer epochs per batch
        batch_size=16,  # Smaller batch size
        verbose=1
    )
    # Clear memory
    del X1_train, X2_train, Y_train
    gc.collect()
    K.clear_session()  # Clear Keras session to free memory

# Re-initialize the network to ensure we have a clean session
K.clear_session()
siamese, base_network = siamese_network()

# Calculate similarity between the two uploaded images
similarity_score = siamese.predict([
    np.expand_dims(image1, axis=0),
    np.expand_dims(image2, axis=0)
])[0][0]

# Extract feature maps - process one image at a time to save memory
_, feature_maps1 = base_network.predict(np.expand_dims(image1, axis=0))
del image1  # Free memory
gc.collect()

_, feature_maps2 = base_network.predict(np.expand_dims(image2, axis=0))

# Compute difference map
diff_map = np.abs(feature_maps1 - feature_maps2)
# Free memory
del feature_maps1
gc.collect()

# Process the difference map
diff_map = np.mean(diff_map, axis=-1)  # Average across channels
diff_map = (diff_map - diff_map.min()) / (diff_map.max() - diff_map.min() + 1e-8)  # Normalize

# Resize the difference map to match the original image size
diff_map_resized = cv2.resize(diff_map[0], (224, 224), interpolation=cv2.INTER_LINEAR)

# Free memory
del diff_map
gc.collect()

# Reload images for visualization
image1 = preprocess_image(image_paths[0])
image2 = preprocess_image(image_paths[1])

# Create a simpler visualization that uses less memory
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.title("Image Before")
plt.imshow(image1)
plt.axis('off')

plt.subplot(1, 3, 2)
plt.title("Image After")
plt.imshow(image2)
plt.axis('off')

plt.subplot(1, 3, 3)
plt.title(f"Difference Map\nSimilarity: {similarity_score:.3f}")
plt.imshow(diff_map_resized, cmap='hot')
plt.colorbar(label='Difference Magnitude')
plt.axis('off')

plt.tight_layout()
plt.show()

print(f"\nSimilarity Score: {similarity_score:.3f}")
print("Interpretation:")
print("0.0-0.2: Very Different")
print("0.2-0.8: Moderately Similar")
print("0.8-1.0: Very Similar")

# Free remaining memory
del image1, image2, diff_map_resized, base_network, siamese
gc.collect()
K.clear_session()